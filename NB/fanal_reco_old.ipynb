{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em;color:purple; font-style:bold\">\n",
    "<br>FANAL RECONSTRUCTION</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the pseudo-reconstruction phase made in FANAL starting from MC data and finally providing a collection of voxels per event.\n",
    "Following the \"FANAL\" way this is done in two different steps:\n",
    "> * Energy Smearing + Smeared energy filter\n",
    "> * Position Smearing + Fiducial filter\n",
    "\n",
    "(Although they have been grouped in the same loop ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECONSTRUCTION PROCEDURE\n",
    "\n",
    "The reconstruction procedure has two well different steps: one related with energy smearing, and the other with positions. The latest one will be run only for the events that pass the smear-energy filter.\n",
    "\n",
    "Energy-smearing step:\n",
    "\n",
    "> * The smearing energy step, takes the true event energy deposited in the ACTIVE volume, and scales FWHM at Qbb to this energy to get the appropriate sigma. The total event true energy is gaussianly smeared according to this sigma.\n",
    "> * According to the calculated event smeared energy, a filter is applied to select the relevant events for our purposes.\n",
    "> * For those events that passed the smaear-energy filter, the corresponding hit energies are accordingly smeared.\n",
    "\n",
    "Position-smearing step (only run for those events that passed the smear-energy filter)\n",
    "> * Translate hit Z-positions according to the time-hit (relevant for Bi214)\n",
    "> * Filter those hits fitting outside the ACTIVE volume (due to previous translation)\n",
    "> * Voxelize taking as input the ACTIVE hits with smeared-energy, and translated positions\n",
    "> * Check event fiduciality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing general stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General importings\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import numpy  as np\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specific IC stuff\n",
    "import invisible_cities.core.system_of_units  as     units\n",
    "\n",
    "from invisible_cities.cities.components       import city\n",
    "from invisible_cities.core.configure          import configure\n",
    "from invisible_cities.evm.event_model         import MCHit\n",
    "from invisible_cities.reco.paolina_functions  import voxelize_hits\n",
    "from invisible_cities.reco.tbl_functions      import filters as tbl_filters\n",
    "\n",
    "#\n",
    "from invisible_cities.io.mcinfo_io import get_event_numbers_in_file\n",
    "from invisible_cities.io.mcinfo_io import load_mchits_df\n",
    "from invisible_cities.io.mcinfo_io import load_mcparticles_df\n",
    "\n",
    "\n",
    "# Specific fanal stuff\n",
    "from fanal.reco.reco_io_functions import get_reco_group_name\n",
    "\n",
    "from fanal.reco.reco_io_functions import get_event_reco_data\n",
    "from fanal.reco.reco_io_functions import get_events_reco_dict\n",
    "from fanal.reco.reco_io_functions import extend_events_reco_dict\n",
    "from fanal.reco.reco_io_functions import store_events_reco_dict\n",
    "from fanal.reco.reco_io_functions import store_events_reco_counters\n",
    "from fanal.reco.reco_io_functions import get_voxels_reco_dict\n",
    "from fanal.reco.reco_io_functions import extend_voxels_reco_dict\n",
    "from fanal.reco.reco_io_functions import store_voxels_reco_dict\n",
    "\n",
    "from fanal.reco.energy        import get_mc_energy\n",
    "from fanal.reco.energy        import smear_evt_energy\n",
    "from fanal.reco.energy        import smear_hit_energies\n",
    "\n",
    "from fanal.reco.position      import translate_hit_positions\n",
    "from fanal.reco.position      import check_event_fiduciality\n",
    "\n",
    "from fanal.core.logger        import get_logger\n",
    "from fanal.core.detector      import get_active_size\n",
    "from fanal.core.detector      import get_fiducial_size\n",
    "from fanal.core.fanal_types   import DetName\n",
    "\n",
    "from fanal.mc.mc_io_functions import load_mc_particles\n",
    "from fanal.mc.mc_io_functions import load_mc_hits\n",
    "from fanal.mc.mc_io_functions import get_num_mc_particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA NEEDED\n",
    "Qbb  = 2457.83 * units.keV\n",
    "DRIFT_VELOCITY = 1. * units.mm / units.mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@city\n",
    "def fanal_reco(det_name,          # Detector name: 'new', 'next100', 'next500'\n",
    "               event_type,        # Event type: 'bb0nu', 'Tl208', 'Bi214'\n",
    "               fwhm,              # FWHM at Qbb\n",
    "               e_min,             # Minimum smeared energy for energy filtering\n",
    "               e_max,             # Maximum smeared energy for energy filtering\n",
    "               voxel_size,        # Voxel size (x, y, z)\n",
    "               voxel_Eth,         # Voxel energy threshold\n",
    "               veto_width,        # Veto width for fiducial filtering\n",
    "               min_veto_e,        # Minimum energy in veto for fiducial filtering\n",
    "               files_in,          # Input files\n",
    "               event_range,       # Range of events to analyze: all, ... ??\n",
    "               file_out,          # Output file\n",
    "               compression,       # Compression: 'ZLIB1', 'ZLIB4', 'ZLIB5', 'ZLIB9', 'BLOSC5', 'BLZ4HC5'\n",
    "               verbosity_level):\n",
    "    \n",
    "    \n",
    "    ### LOGGER\n",
    "    logger = get_logger('FanalReco', verbosity_level)\n",
    "\n",
    "    \n",
    "    ### DETECTOR NAME & its ACTIVE dimensions\n",
    "    det_name          = getattr(DetName, det_name)\n",
    "    ACTIVE_dimensions = get_active_size(det_name)\n",
    "    fid_dimensions    = get_fiducial_size(det_name, veto_width)\n",
    "\n",
    "    \n",
    "    ### RECONSTRUCTION DATA\n",
    "    # Smearing energy settings\n",
    "    fwhm_Qbb  = fwhm * Qbb\n",
    "    sigma_Qbb = fwhm_Qbb / 2.355\n",
    "    assert e_max > e_min, 'SmE_filter settings not valid. e_max must be higher than e_min.'\n",
    "\n",
    "    \n",
    "    ### PRINTING GENERAL INFO\n",
    "    print('\\n***********************************************************************************')\n",
    "    print('***** Detector:          {}'.format(det_name.name))\n",
    "    print('***** Reconstructing:    {} events'.format(event_type))\n",
    "    print('***** Energy Resolution: {:.2f}% fwhm at Qbb'.format(fwhm / units.perCent))\n",
    "    print('***** Voxel Size:        ({}, {}, {}) mm'.format(voxel_size[0] / units.mm,\n",
    "                                                            voxel_size[1] / units.mm,\n",
    "                                                            voxel_size[2] / units.mm))\n",
    "    print('***********************************************************************************\\n')\n",
    "\n",
    "    print('* Sigma at Qbb: {:.3f} keV.\\n'.format(sigma_Qbb / units.keV))\n",
    "\n",
    "    print('* Voxel_size: ({}, {}, {}) mm'.format(voxel_size[0] / units.mm,\n",
    "                                                 voxel_size[1] / units.mm,\n",
    "                                                 voxel_size[2] / units.mm))\n",
    "    print('  Voxel Eth:  {:4.1f} keV\\n'.format(voxel_Eth/units.keV))\n",
    "\n",
    "    print('* Detector-Active dimensions [mm]:  Zmin: {:7.1f}   Zmax: {:7.1f}   Rmax: {:7.1f}'\n",
    "          .format(ACTIVE_dimensions.z_min, ACTIVE_dimensions.z_max,\n",
    "                  ACTIVE_dimensions.rad))\n",
    "    print('         ... fiducial limits [mm]:  Zmin: {:7.1f}   Zmax: {:7.1f}   Rmax: {:7.1f}\\n'\n",
    "          .format(fid_dimensions.z_min, fid_dimensions.z_max, fid_dimensions.rad))\n",
    "\n",
    "    print('* {0} {1} input files:'.format(len(files_in), event_type))\n",
    "    for iFileName in files_in:\n",
    "        print(' ', iFileName)\n",
    "\n",
    "\n",
    "    ### OUTPUT FILE, ITS GROUPS & ATTRIBUTES\n",
    "    # Output file\n",
    "    oFile = tb.open_file(file_out, 'w', filters=tbl_filters(compression))\n",
    "\n",
    "    # Reco group Name\n",
    "    reco_group_name = get_reco_group_name(fwhm/units.perCent, voxel_size)\n",
    "    oFile.create_group('/', 'FANAL')\n",
    "    oFile.create_group('/FANAL', reco_group_name[7:])\n",
    "\n",
    "    print('\\n* Output file name:', file_out)\n",
    "    print('  Reco group name:  {}\\n'.format(reco_group_name))\n",
    "        \n",
    "    # Attributes\n",
    "    oFile.set_node_attr(reco_group_name, 'input_sim_files',           files_in)\n",
    "    oFile.set_node_attr(reco_group_name, 'event_type',                event_type)\n",
    "    oFile.set_node_attr(reco_group_name, 'energy_resolution',         fwhm/units.perCent)\n",
    "    oFile.set_node_attr(reco_group_name, 'voxel_sizeX',               voxel_size[0])\n",
    "    oFile.set_node_attr(reco_group_name, 'voxel_sizeY',               voxel_size[1])\n",
    "    oFile.set_node_attr(reco_group_name, 'voxel_sizeZ',               voxel_size[2])\n",
    "    oFile.set_node_attr(reco_group_name, 'voxel_Eth',                 voxel_Eth)\n",
    "    oFile.set_node_attr(reco_group_name, 'smE_filter_Emin',           e_min)\n",
    "    oFile.set_node_attr(reco_group_name, 'smE_filter_Emax',           e_max)\n",
    "    oFile.set_node_attr(reco_group_name, 'fiducial_filter_VetoWidth', veto_width)\n",
    "    oFile.set_node_attr(reco_group_name, 'fiducial_filter_MinVetoE',  min_veto_e)\n",
    "\n",
    "\n",
    "    ### DATA TO STORE\n",
    "    # Event counters\n",
    "    simulated_events = 0\n",
    "    stored_events    = 0\n",
    "    analyzed_events  = 0\n",
    "    toUpdate_events  = 1\n",
    "    \n",
    "    # Dictionaries for events & voxels data\n",
    "    events_dict = get_events_reco_dict()\n",
    "    voxels_dict = get_voxels_reco_dict()\n",
    "\n",
    "\n",
    "    ### RECONSTRUCTION PROCEDURE\n",
    "    # Looping through all the input files\n",
    "    for iFileName in files_in:\n",
    "        # Updating simulated and stored event counters\n",
    "        configuration_df = pd.read_hdf(iFileName, '/MC/configuration', mode='r')\n",
    "        simulated_events += int(configuration_df[configuration_df.param_key=='num_events'].param_value)\n",
    "        stored_events    += int(configuration_df[configuration_df.param_key=='saved_events'].param_value)\n",
    "        \n",
    "        # Getting event numbers\n",
    "        file_event_numbers = get_event_numbers_in_file(iFileName)\n",
    "        print('* Processing {0}  ({1} events) ...'.format(iFileName, len(file_event_numbers)))\n",
    "        \n",
    "        # Getting mc hits & particles\n",
    "        file_mcHits  = load_mchits_df(iFileName)\n",
    "        file_mcParts = load_mcparticles_df(iFileName)\n",
    "        \n",
    "        # Looping through all the events in iFile\n",
    "        for event_number in file_event_numbers:\n",
    "\n",
    "            # Updating counter of analyzed events\n",
    "            analyzed_events += 1\n",
    "            logger.info('Reconstructing event Id: {0} ...'.format(event_number))\n",
    "\n",
    "            # Getting event data\n",
    "            event_data = get_event_reco_data()\n",
    "            event_data['event_id'] = event_number\n",
    "            \n",
    "            event_mcHits  = file_mcHits.loc[event_number, :]\n",
    "            active_mcHits = event_mcHits[event_mcHits.label == 'ACTIVE'].copy()\n",
    "            event_mcParts = file_mcParts.loc[event_number, :]\n",
    "\n",
    "            event_data['num_MCparts'] = len(event_mcParts)\n",
    "            event_data['num_MChits']  = len(active_mcHits)\n",
    "            \n",
    "            # The event mc energy is the sum of the energy of all the hits except\n",
    "            # for Bi214 events, in which the number of S1 in the event is considered\n",
    "            if (event_type == 'Bi214'):\n",
    "                event_data['mcE'] = get_mc_energy(active_mcHits)\n",
    "            else:\n",
    "                event_data['mcE'] = active_mcHits.energy.sum()\n",
    "            \n",
    "            # Smearing the event energy\n",
    "            event_data['smE'] = smear_evt_energy(event_data['mcE'], sigma_Qbb, Qbb)\n",
    "\n",
    "            # Applying the smE filter\n",
    "            event_data['smE_filter'] = (e_min <= event_data['smE'] <= e_max)\n",
    "\n",
    "            # Verbosing\n",
    "            logger.info('  Num mcHits: {0:3}   mcE: {1:.1f} keV   smE: {2:.1f} keV   smE_filter: {3}' \\\n",
    "                        .format(event_data['num_MChits'], event_data['mcE']/units.keV,\n",
    "                                event_data['smE']/units.keV, event_data['smE_filter']))\n",
    "                \n",
    "            # For those events passing the smE filter:\n",
    "            if event_data['smE_filter']:\n",
    "\n",
    "                # Smearing hit energies\n",
    "                smearing_factor = event_data['smE'] / event_data['mcE']\n",
    "                active_mcHits['smE'] = active_mcHits['energy'] * smearing_factor\n",
    "\n",
    "                # Translating hit Z positions from delayed hits\n",
    "                translate_hit_positions(det_name, active_mcHits, DRIFT_VELOCITY)                \n",
    "                active_mcHits = active_mcHits[(active_mcHits.shifted_z < ACTIVE_dimensions.z_max) &\n",
    "                                              (active_mcHits.shifted_z > ACTIVE_dimensions.z_min)]\n",
    "\n",
    "                # Creating the IChits with the smeared energies and translated Z positions\n",
    "                # to be passed to paolina functions\n",
    "                #IChits = []\n",
    "                #for i, hit in active_mcHits.iterrows():\n",
    "                #    IChit = MCHit((hit.x, hit.y, hit.shifted_z), hit.time, hit.smE, 'ACTIVE')\n",
    "                #    IChits.append(IChit)                \n",
    "                IChits = active_mcHits.apply(lambda hit: MCHit((hit.x, hit.y, hit.shifted_z),\n",
    "                                             hit.time, hit.smE, 'ACTIVE'), axis=1).tolist()\n",
    "\n",
    "                # Voxelizing using the IChits ...\n",
    "                event_voxels = voxelize_hits(IChits, voxel_size, strict_voxel_size=False)\n",
    "                event_data['num_voxels'] = len(event_voxels)\n",
    "                eff_voxel_size = event_voxels[0].size\n",
    "                event_data['voxel_sizeX'] = eff_voxel_size[0]\n",
    "                event_data['voxel_sizeY'] = eff_voxel_size[1]\n",
    "                event_data['voxel_sizeZ'] = eff_voxel_size[2]\n",
    "    \n",
    "                # Storing voxels info\n",
    "                for voxel_id in range(len(event_voxels)):\n",
    "                    extend_voxels_reco_dict(voxels_dict, event_number, voxel_id,\n",
    "                                            event_voxels[voxel_id], voxel_Eth)\n",
    "    \n",
    "                # Check fiduciality\n",
    "                event_data['voxels_minZ'], event_data['voxels_maxZ'], event_data['voxels_maxRad'], \\\n",
    "                event_data['veto_energy'], event_data['fid_filter'] = \\\n",
    "                check_event_fiduciality(det_name, veto_width, min_veto_e, event_voxels)\n",
    "                   \n",
    "                # Verbosing\n",
    "                logger.info('  NumVoxels: {:3}   minZ: {:.1f} mm   maxZ: {:.1f} mm   maxR: {:.1f} mm   veto_E: {:.1f} keV   fid_filter: {}' \\\n",
    "                            .format(event_data['num_voxels'], event_data['voxels_minZ'],\n",
    "                                    event_data['voxels_maxZ'], event_data['voxels_maxRad'],\n",
    "                                    event_data['veto_energy'] / units.keV, event_data['fid_filter']))\n",
    "                \n",
    "                for voxel in event_voxels:\n",
    "                    logger.debug('    Voxel pos: ({:5.1f}, {:5.1f}, {:5.1f}) mm   E: {:5.1f} keV'\\\n",
    "                                 .format(voxel.X/units.mm, voxel.Y/units.mm, voxel.Z/units.mm, voxel.E/units.keV))\n",
    "\n",
    "            # Storing event_data\n",
    "            extend_events_reco_dict(events_dict, event_data)\n",
    "\n",
    "            # Verbosing\n",
    "            if (not(analyzed_events % toUpdate_events)):\n",
    "                print('* Num analyzed events: {}'.format(analyzed_events))\n",
    "            if (analyzed_events == (10 * toUpdate_events)): toUpdate_events *= 10\n",
    "            \n",
    "\n",
    "    ### STORING  RECONSTRUCTION DATA\n",
    "    print('* Total analyzed events: {}'.format(analyzed_events))\n",
    "\n",
    "    # Storing events and voxels dataframes\n",
    "    print('\\n* Storing data in the output file ...\\n  {}\\n'.format(file_out))\n",
    "    store_events_reco_dict(file_out, reco_group_name, events_dict)\n",
    "    store_voxels_reco_dict(file_out, reco_group_name, voxels_dict)\n",
    "    \n",
    "    # Storing event counters as attributes\n",
    "    smE_filter_events = sum(events_dict['smE_filter'])\n",
    "    fid_filter_events = sum(events_dict['fid_filter'])\n",
    "    store_events_reco_counters(oFile, reco_group_name, simulated_events, stored_events,\n",
    "                               smE_filter_events, fid_filter_events)\n",
    "    \n",
    "    \n",
    "    ### Ending ...\n",
    "    oFile.close()\n",
    "    print('\\n* Reconstruction done !!\\n')\n",
    "    \n",
    "    # Printing reconstruction numbers\n",
    "    print('* Event counters ...')\n",
    "    print('''  Simulated events:  {0:9}\n",
    "  Stored events:     {1:9}\n",
    "  smE_filter events: {2:9}\n",
    "  fid_filter events: {3:9}'''\n",
    "          .format(simulated_events, stored_events, smE_filter_events, fid_filter_events))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING THE RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco_sets import recos\n",
    "print(\"Available reconstruction sets ...\\n\")\n",
    "for key in recos.keys(): print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "current_reco    = recos['next100_bb0nu_07_10x10x10']\n",
    "compression     = 'ZLIB4'\n",
    "#verbosity_level = 'DEBUG'\n",
    "verbosity_level = 'WARNING'\n",
    "#verbosity_level = 'INFO'\n",
    "\n",
    "#%mprun -f fanal_reco fanal_reco(det_name = current_reco['det_name'], \\\n",
    "#%lprun -f fanal_reco fanal_reco(det_name = current_reco['det_name'], \\\n",
    "#                                event_type = current_reco['event_type'], \\\n",
    "#                                fwhm = current_reco['fwhm'], \\\n",
    "#                                e_min = current_reco['e_min'], \\\n",
    "#                                e_max = current_reco['e_max'], \\\n",
    "#                                voxel_size = current_reco['voxel_size'], \\\n",
    "#                                voxel_Eth = current_reco['voxel_Eth'], \\\n",
    "#                                veto_width = current_reco['veto_width'], \\\n",
    "#                                min_veto_e = current_reco['min_veto_e'], \\\n",
    "#                                files_in = current_reco['files_in'], \\\n",
    "#                                event_range = current_reco['event_range'], \\\n",
    "#                                file_out = current_reco['file_out'], \\\n",
    "#                                compression = compression, \\\n",
    "#                                verbosity_level = verbosity_level)\n",
    "\n",
    "\n",
    "fanal_reco(det_name        = current_reco['det_name'],\n",
    "           event_type      = current_reco['event_type'],\n",
    "           fwhm            = current_reco['fwhm'],\n",
    "           e_min           = current_reco['e_min'],\n",
    "           e_max           = current_reco['e_max'],\n",
    "           voxel_size      = current_reco['voxel_size'],\n",
    "           voxel_Eth       = current_reco['voxel_Eth'],\n",
    "           veto_width      = current_reco['veto_width'],\n",
    "           min_veto_e      = current_reco['min_veto_e'],\n",
    "           files_in        = current_reco['files_in'],\n",
    "           event_range     = current_reco['event_range'],\n",
    "           file_out        = current_reco['file_out'],\n",
    "           compression     = compression,\n",
    "           verbosity_level = verbosity_level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERBOSING THE RECONSTRUCTION ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DET_NAME        = getattr(DetName, current_reco['det_name'])\n",
    "RECO_FILE_NAME  = current_reco['file_out']\n",
    "RECO_GROUP_NAME = get_reco_group_name(current_reco['fwhm'] / units.perCent, current_reco['voxel_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbosing the event counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(RECO_FILE_NAME, mode='r') as reco_file:\n",
    "    simulated_events  = reco_file.get_node_attr(RECO_GROUP_NAME, 'simulated_events')\n",
    "    stored_events     = reco_file.get_node_attr(RECO_GROUP_NAME, 'stored_events')\n",
    "    smE_filter_events = reco_file.get_node_attr(RECO_GROUP_NAME, 'smE_filter_events')\n",
    "    fid_filter_events = reco_file.get_node_attr(RECO_GROUP_NAME, 'fid_filter_events')\n",
    "\n",
    "print('* Event counters ...')\n",
    "print('''  Simulated events:  {0:9}\n",
    "  Stored events:     {1:9}\n",
    "  smE_filter events: {2:9}\n",
    "  fid_filter events: {3:9}'''\n",
    "      .format(simulated_events, stored_events, smE_filter_events, fid_filter_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbosing the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_hdf(RECO_FILE_NAME, RECO_GROUP_NAME + '/events')\n",
    "voxels_df = pd.read_hdf(RECO_FILE_NAME, RECO_GROUP_NAME + '/voxels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_smE_True = events_df[events_df.smE_filter == True]\n",
    "events_df_fid_True = events_df[events_df.fid_filter == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events_df[events_df.mcE > 0.])#.mcE.hist(range=[2,52], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_smE_True.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_fid_True.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_df[voxels_df.negli]#.loc[50010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating some histograms ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting event counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,4))\n",
    "\n",
    "counters_toPlot = {'Simulated Events':  simulated_events,\n",
    "                   'Stored Events':     stored_events,\n",
    "                   'smE_filter Events': smE_filter_events,\n",
    "                   'fid_filter Events': fid_filter_events}\n",
    "\n",
    "plt.bar(range(len(counters_toPlot)), list(counters_toPlot.values()), align='center',\n",
    "        color=['b', 'r', 'c', 'y'], yerr=np.sqrt([simulated_events, stored_events,\n",
    "                                                  smE_filter_events, fid_filter_events]))\n",
    "plt.xticks(range(len(counters_toPlot)), list(counters_toPlot.keys()), rotation='30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting event energies (MC & Smeared) of every event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,5))\n",
    "num_bins = 50\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.hist(events_df.mcE, num_bins, [2.3, 2.6])\n",
    "plt.xlabel('Event energy [MeV]', size=12)\n",
    "plt.ylabel('Num. events', size=12)\n",
    "plt.title('MonteCarlo Event Energy [MeV]')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.hist(events_df.smE, num_bins, [2.3, 2.6])\n",
    "plt.xlabel('Event energy [MeV]', size=12)\n",
    "plt.ylabel('Num. events', size=12)\n",
    "plt.title('Smeared Event Energy [MeV]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the number of voxels per event that passed the \"Smeared Energy\" filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_smE_True['num_voxels'].value_counts().head(50).sort_index().plot(kind='bar', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the voxels energies for all the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_df[voxels_df.negli == False].hist('E', figsize =(8,4),\n",
    "                                         bins = 50, range = (0., 0.5),\n",
    "                                         grid = True, log = False,\n",
    "                                         label = 'Voxel Energy', xlabelsize = 12,\n",
    "                                         density = False, cumulative = False,\n",
    "                                         histtype = 'stepfilled',\n",
    "                                         # Type of Histogram ('bar', 'barstacked', 'step', 'stepfilled')\n",
    "                                         orientation = 'vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the spatial distribution of voxels from fiducial events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_dimensions = get_active_size(DET_NAME)\n",
    "\n",
    "#fid_voxels = voxels_df[voxels_df.event_indx.isin(events_df_fid_True.index)]\n",
    "fid_voxels = voxels_df.loc[events_df_fid_True.index]\n",
    "\n",
    "fig = plt.figure(figsize = (18,5))\n",
    "num_bins = int(ACTIVE_dimensions.z_max/10)\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "plt.hist(fid_voxels.X, num_bins, [-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad])\n",
    "plt.title('X [mm]', size=14)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "plt.hist(fid_voxels.Y, num_bins, [-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad])\n",
    "plt.title('Y [mm]', size=14)\n",
    "\n",
    "ax3 = fig.adax1 = fig.add_subplot(1, 3, 3)\n",
    "plt.hist(fid_voxels.Z, num_bins, [ACTIVE_dimensions.z_min, ACTIVE_dimensions.z_max])\n",
    "plt.title('Z [mm]', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   matplotlib.colors import LogNorm\n",
    "\n",
    "fig = plt.figure(figsize = (18,5.5))\n",
    "num_bins = int(ACTIVE_dimensions.z_max/10)\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "plt.hist2d(fid_voxels.X, fid_voxels.Y, num_bins, [[-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad],\n",
    "                                                  [-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad]],\n",
    "           norm=LogNorm())\n",
    "plt.xlabel('X [mm]', size=12)\n",
    "plt.ylabel('Y [mm]', size=12)\n",
    "plt.title('X-Y [mm]', size=14)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "plt.hist2d(fid_voxels.X, fid_voxels.Z, num_bins, [[-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad],\n",
    "                                                  [ACTIVE_dimensions.z_min, ACTIVE_dimensions.z_max]],\n",
    "           norm=LogNorm())\n",
    "plt.xlabel('X [mm]', size=12)\n",
    "plt.ylabel('Z [mm]', size=12)\n",
    "plt.title('X-Z [mm]', size=14)\n",
    "\n",
    "ax3 = fig.adax1 = fig.add_subplot(1, 3, 3)\n",
    "plt.hist2d(fid_voxels.Y, fid_voxels.Z, num_bins, [[-ACTIVE_dimensions.rad, ACTIVE_dimensions.rad],\n",
    "                                                  [ACTIVE_dimensions.z_min, ACTIVE_dimensions.z_max]],\n",
    "           norm=LogNorm())\n",
    "plt.xlabel('Y [mm]', size=12)\n",
    "plt.ylabel('Z [mm]', size=12)\n",
    "plt.title('Y-Z [mm]', size=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histogram of voxel sizes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,5))\n",
    "num_bins = 45\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "plt.hist(events_df_fid_True.voxel_sizeX, num_bins, [0, 15])\n",
    "plt.title('SizeX [mm]', size=14)\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 2)\n",
    "plt.hist(events_df_fid_True.voxel_sizeY, num_bins, [0, 15])\n",
    "plt.title('SizeY [mm]', size=14)\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 3)\n",
    "plt.hist(events_df_fid_True.voxel_sizeZ, num_bins, [0, 15])\n",
    "plt.title('SizeZ [mm]', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_smE_True.hist(['mcE', 'smE'], bins=20,  figsize = (16,6), range = [2.4, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "num_bins = 50\n",
    "\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "plt.hist(events_df_smE_True.mcE, num_bins, [2.39,2.51])\n",
    "plt.xlabel('Total energy (MeV)')\n",
    "ax1 = fig.add_subplot(2, 1, 2)\n",
    "plt.hist(events_df_smE_True.smE, num_bins, [2.39,2.51])\n",
    "plt.xlabel('Total energy (MeV)')\n",
    "\n",
    "from scipy.stats import norm\n",
    "(mu,sigma) = norm.fit(events_df[((events_df.smE>2.445) & (events_df.smE<2.475))].smE)\n",
    "print('mean: {0:.4f} MeV  sigma: {1:.4f} MeV'.format(mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(voxels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.smE_filter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
