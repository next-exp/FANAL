{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em; color:purple; font-style:bold\">\n",
    "<br>FANAL ANALYSIS</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the analysys phase made in FANALIC starting from the pseudo-reconstructed data performed also in FANALIC and dealing with the topology and the ROI stuff.\n",
    "Following the \"FANAL\" way this is done in different steps:\n",
    "> * Tracks building and filtering\n",
    "> * Blobs  building and filtering\n",
    "> * ROI filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPOLOGY & ROI ANALYSIS\n",
    "\n",
    "In this section we will go through the following steps:\n",
    "* Discard voxels whose energies are below the threshold, and assign their energies to closest neighbours\n",
    "* Make tracks\n",
    "* Order tracks according to their energies, and filter those with energy lower than threshold\n",
    "* Apply the tracks filter\n",
    "* Get 'hottest' track blobs\n",
    "* Apply blobs filter\n",
    "* Apply ROI filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing general stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy  as np\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib.colors import LogNorm\n",
    "\n",
    "# Specific IC stuff\n",
    "import invisible_cities.core.system_of_units  as units\n",
    "from invisible_cities.cities.components       import city\n",
    "from invisible_cities.core.configure          import configure\n",
    "from invisible_cities.evm.event_model         import Voxel\n",
    "from invisible_cities.reco.tbl_functions      import filters as tbl_filters\n",
    "from invisible_cities.reco.paolina_functions  import make_track_graphs\n",
    "from invisible_cities.reco.paolina_functions  import blob_energies\n",
    "\n",
    "# Specific fanalIC stuff\n",
    "from fanal.reco.reco_io_functions import get_reco_group_name\n",
    "from fanal.ana.ana_io_functions   import get_ana_group_name\n",
    "\n",
    "from fanal.ana.ana_io_functions   import get_event_ana_data\n",
    "from fanal.ana.ana_io_functions   import get_events_ana_dict\n",
    "from fanal.ana.ana_io_functions   import extend_events_ana_dict\n",
    "from fanal.ana.ana_io_functions   import store_events_ana_dict\n",
    "from fanal.ana.ana_io_functions   import store_events_ana_counters\n",
    "\n",
    "from fanal.ana.ana_io_functions   import get_voxels_ana_dict\n",
    "from fanal.ana.ana_io_functions   import extend_voxels_ana_dict\n",
    "from fanal.ana.ana_io_functions   import store_voxels_ana_dict\n",
    "\n",
    "from fanal.core.fanal_types  import DetName\n",
    "from fanal.core.logger       import get_logger\n",
    "\n",
    "from fanal.ana.ana_functions import get_new_energies\n",
    "from fanal.ana.ana_functions import get_voxel_track_relations\n",
    "from fanal.ana.ana_functions import process_tracks\n",
    "\n",
    "#from fanal.mc.mc_utilities import print_mc_event\n",
    "#from fanal.mc.mc_utilities import plot_mc_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@city\n",
    "def fanal_ana(det_name,       # Detector name: 'new', 'next100', 'next500'\n",
    "              event_type,     # Event type: 'bb0nu', 'Tl208', 'Bi214'\n",
    "              fwhm,           # FWHM at Qbb\n",
    "              voxel_size,     # Voxel size (x, y, z)\n",
    "              track_Eth,      # Track energy threshold\n",
    "              max_num_tracks, # Maximum number of tracks\n",
    "              blob_radius,    # Blob radius\n",
    "              blob_Eth,       # Blob energy threshold\n",
    "              roi_Emin,       # ROI minimum energy\n",
    "              roi_Emax,       # ROI maximum energy\n",
    "              files_in,       # Input files\n",
    "              event_range,    # Range of events to analyze: all, ... ??\n",
    "              file_out,       # Output file\n",
    "              compression,    # Compression: 'ZLIB1', 'ZLIB4', 'ZLIB5', 'ZLIB9', 'BLOSC5', 'BLZ4HC5'\n",
    "              verbosity_level):\n",
    "\n",
    "    ### LOGGER\n",
    "    logger = get_logger('FanalAna', verbosity_level)\n",
    "\n",
    "    ### DETECTOR NAME\n",
    "    det_name = getattr(DetName, det_name)\n",
    "\n",
    "    \n",
    "    ### PRINTING GENERAL INFO\n",
    "    print('\\n***********************************************************************************')\n",
    "    print('***** Detector: {}'.format(det_name.name))\n",
    "    print('***** Analizing {} events'.format(event_type))\n",
    "    print('***** Energy Resolution: {:.2f}% FWFM at Qbb'.format(fwhm / units.perCent))\n",
    "    print('***** Voxel Size: ({}, {}, {}) mm'.format(voxel_size[0] / units.mm,\n",
    "                                                     voxel_size[1] / units.mm,\n",
    "                                                     voxel_size[2] / units.mm))\n",
    "    print('***********************************************************************************\\n')\n",
    "\n",
    "    print('* Track Eth: {:4.1f} keV   Max Num Tracks: {}\\n' \\\n",
    "          .format(track_Eth/units.keV, max_num_tracks))\n",
    "    print('* Blob radius: {:.1f} mm   Blob Eth: {:4.1f} keV\\n' \\\n",
    "          .format(blob_radius, blob_Eth / units.keV))\n",
    "    print('* ROI limits: [{:4.1f}, {:4.1f}] keV\\n' \\\n",
    "          .format(roi_Emin/units.keV, roi_Emax/units.keV))\n",
    "    \n",
    "    \n",
    "    ### INPUT RECONSTRUCTION FILES AND GROUP\n",
    "    reco_group_name = get_reco_group_name(fwhm/units.perCent, voxel_size)\n",
    "    print('* {} {} input reco file names:'.format(len(files_in), event_type))\n",
    "    for iFileName in files_in: print(' ', iFileName)\n",
    "    print('  Reco group name: {}\\n'.format(reco_group_name))    \n",
    "    \n",
    "    \n",
    "    ### OUTPUT FILE, ITS GROUPS & ATTRIBUTES\n",
    "    # Output analysis file\n",
    "    oFile = tb.open_file(file_out, 'w', filters=tbl_filters(compression))\n",
    "\n",
    "    # Analysis group Name\n",
    "    ana_group_name = get_ana_group_name(fwhm/units.perCent, voxel_size)\n",
    "    oFile.create_group('/', 'FANAL')\n",
    "    oFile.create_group('/FANAL', ana_group_name[7:])\n",
    "    \n",
    "    print('* Output analysis file name:', file_out)\n",
    "    print('  Ana group name: {}\\n'.format(ana_group_name))\n",
    "\n",
    "    # Attributes\n",
    "    oFile.set_node_attr(ana_group_name, 'input_reco_files', files_in)\n",
    "    oFile.set_node_attr(ana_group_name, 'input_reco_group', reco_group_name)\n",
    "    oFile.set_node_attr(ana_group_name, 'event_type', event_type)\n",
    "    oFile.set_node_attr(ana_group_name, 'energy_resolution', fwhm/units.perCent)\n",
    "    oFile.set_node_attr(ana_group_name, 'track_Eth', track_Eth)\n",
    "    oFile.set_node_attr(ana_group_name, 'max_num_tracks', max_num_tracks)\n",
    "    oFile.set_node_attr(ana_group_name, 'blob_radius', blob_radius)\n",
    "    oFile.set_node_attr(ana_group_name, 'blob_Eth', blob_Eth)\n",
    "    oFile.set_node_attr(ana_group_name, 'roi_Emin', roi_Emin)\n",
    "    oFile.set_node_attr(ana_group_name, 'roi_Emax', roi_Emax)    \n",
    "    \n",
    "\n",
    "    ### DATA TO STORE\n",
    "    # Event counters\n",
    "    simulated_events     = 0\n",
    "    stored_events        = 0\n",
    "    smE_filter_events    = 0\n",
    "    fid_filter_events    = 0\n",
    "    tracks_filter_events = 0\n",
    "    blobs_filter_events  = 0\n",
    "    roi_filter_events    = 0\n",
    "\n",
    "    analyzed_events = 0\n",
    "    toUpdate_events = 1\n",
    "\n",
    "    # Dictionaries for events & voxels data\n",
    "    events_dict = get_events_ana_dict()\n",
    "    voxels_dict = get_voxels_ana_dict()\n",
    "\n",
    "    events_reco_df = pd.DataFrame()\n",
    "    voxels_reco_df = pd.DataFrame()\n",
    "    \n",
    "    ### ANALYSIS PROCEDURE\n",
    "    print('* Analyzing events ...\\n')\n",
    "\n",
    "    # Looping through all the input files\n",
    "    for iFileName in files_in:\n",
    "        \n",
    "        # Updating reconstruction counters\n",
    "        with tb.open_file(iFileName, mode='r') as reco_file:\n",
    "            simulated_events  += reco_file.get_node_attr(reco_group_name, 'simulated_events')\n",
    "            stored_events     += reco_file.get_node_attr(reco_group_name, 'stored_events')\n",
    "            smE_filter_events += reco_file.get_node_attr(reco_group_name, 'smE_filter_events')\n",
    "            fid_filter_events += reco_file.get_node_attr(reco_group_name, 'fid_filter_events')\n",
    "        \n",
    "        # Getting the events & voxels data from the reconstruction phase\n",
    "        file_events = pd.read_hdf(iFileName, reco_group_name + '/events')\n",
    "        file_voxels = pd.read_hdf(iFileName, reco_group_name + '/voxels')\n",
    "        \n",
    "        # Updating reconstruction dataframes\n",
    "        events_reco_df = pd.concat([events_reco_df, file_events], axis=0)\n",
    "        voxels_reco_df = pd.concat([voxels_reco_df, file_voxels], axis=0)\n",
    "        \n",
    "        print('* Processing {} ...'.format(iFileName))\n",
    "\n",
    "        \n",
    "        ### Looping through all the events that passed the fiducial filter\n",
    "        for event_number, event_df in file_events[file_events.fid_filter].iterrows():        \n",
    "\n",
    "            # Updating counter of analyzed events\n",
    "            analyzed_events += 1\n",
    "            logger.info('Analyzing event Id: {0} ...'.format(event_number))\n",
    "\n",
    "            # Getting event data\n",
    "            event_data = get_event_ana_data()\n",
    "            event_data['event_id'] = event_number\n",
    "            \n",
    "            event_voxels = file_voxels.loc[event_number]\n",
    "            num_event_voxels = len(event_voxels)\n",
    "            num_event_voxels_negli = len(event_voxels[event_voxels.negli])\n",
    "            voxel_dimensions = (event_df.voxel_sizeX,\n",
    "                                event_df.voxel_sizeY,\n",
    "                                event_df.voxel_sizeZ)\n",
    "\n",
    "            logger.info('  Total Voxels: {}   Negli. Voxels: {}   Voxels Size: ({:3.1f}, {:3.1f}, {:3.1f}) mm'\\\n",
    "                        .format(num_event_voxels, num_event_voxels_negli, voxel_dimensions[0],\n",
    "                                voxel_dimensions[1], voxel_dimensions[2]))\n",
    "\n",
    "            # If there is any negligible Voxel, distribute its energy between its neighbours,\n",
    "            # if not, all voxels maintain their previous energies\n",
    "            if num_event_voxels_negli:\n",
    "                event_voxels_newE = get_new_energies(event_voxels)\n",
    "            else:\n",
    "                event_voxels_newE = event_voxels.E.tolist()\n",
    "        \n",
    "            # Translate fanalIC voxels info to IC voxels to make tracks\n",
    "            #ic_voxels = [Voxel(event_voxels.iloc[i].X, event_voxels.iloc[i].Y, event_voxels.iloc[i].Z,\n",
    "            #                   event_voxels_newE[i], voxel_dimensions) for i in range(num_event_voxels)]\n",
    "            ic_voxels = []\n",
    "            for i, voxel in event_voxels.iterrows():\n",
    "                ic_voxel = Voxel(voxel.X, voxel.Y, voxel.Z, event_voxels_newE[i], voxel_dimensions)\n",
    "                ic_voxels.append(ic_voxel)            \n",
    "            \n",
    "            # Make tracks\n",
    "            event_tracks = make_track_graphs(ic_voxels)\n",
    "            num_ini_tracks = len(event_tracks)\n",
    "            logger.info('  Num initial tracks: {:2}'.format(num_ini_tracks))\n",
    "\n",
    "            # Appending to every voxel, the track it belongs to\n",
    "            event_voxels_tracks = get_voxel_track_relations(event_voxels, event_tracks)\n",
    "\n",
    "            # Appending ana-info to this event voxels\n",
    "            extend_voxels_ana_dict(voxels_dict, event_number, event_voxels.index.tolist(),\n",
    "                                   event_voxels_newE, event_voxels_tracks)\n",
    "\n",
    "            # Processing tracks: Getting energies, sorting and filtering ...\n",
    "            event_sorted_tracks = process_tracks(event_tracks, track_Eth)         \n",
    "            event_data['num_tracks'] = len(event_sorted_tracks)\n",
    "\n",
    "            # Getting 3 hottest tracks info\n",
    "            if event_data['num_tracks'] >= 1:\n",
    "                event_data['track0_E']      = event_sorted_tracks[0][0]\n",
    "                event_data['track0_length'] = event_sorted_tracks[0][1]\n",
    "                event_data['track0_voxels'] = len(event_sorted_tracks[0][2].nodes())\n",
    "            if event_data['num_tracks'] >= 2:\n",
    "                event_data['track1_E']      = event_sorted_tracks[1][0]\n",
    "                event_data['track1_length'] = event_sorted_tracks[1][1]\n",
    "                event_data['track1_voxels'] = len(event_sorted_tracks[1][2].nodes())\n",
    "            if event_data['num_tracks'] >= 3:\n",
    "                event_data['track2_E']      = event_sorted_tracks[2][0]\n",
    "                event_data['track2_length'] = event_sorted_tracks[2][1]\n",
    "                event_data['track2_voxels'] = len(event_sorted_tracks[2][2].nodes())\n",
    "            \n",
    "            # Applying the tracks filter consisting on:\n",
    "            # 0 < num tracks < max_num_tracks\n",
    "            # the track length must be longer than 2 times the blob_radius\n",
    "            event_data['tracks_filter'] = ((event_data['num_tracks'] >  0) &\n",
    "                                           (event_data['num_tracks'] <= max_num_tracks) &\n",
    "                                           (event_data['track0_length'] >=  2. * blob_radius))\n",
    "        \n",
    "            # Verbosing\n",
    "            logger.info('  Num final tracks: {:2}  -->  tracks_filter: {}' \\\n",
    "                        .format(event_data['num_tracks'], event_data['tracks_filter']))\n",
    "\n",
    "            \n",
    "            ### For those events passing the tracks filter:\n",
    "            if event_data['tracks_filter']:\n",
    "\n",
    "                # Getting the blob energies of the track with highest energy\n",
    "                event_data['blob1_E'], event_data['blob2_E'] = \\\n",
    "                    blob_energies(event_sorted_tracks[0][2], blob_radius)\n",
    "                \n",
    "                # Applying the blobs filter\n",
    "                event_data['blobs_filter'] = (event_data['blob2_E'] > blob_Eth)\n",
    "               \n",
    "                # Verbosing\n",
    "                logger.info('  Blob 1 energy: {:4.1f} keV   Blob 2 energy: {:4.1f} keV  -->  Blobs filter: {}'\\\n",
    "                            .format(event_data['blob1_E']/units.keV, event_data['blob2_E']/units.keV,\n",
    "                                    event_data['blobs_filter']))\n",
    "\n",
    "                \n",
    "                ### For those events passing the blobs filter:\n",
    "                if event_data['blobs_filter']:\n",
    "\n",
    "                    # Getting the total event smeared energy\n",
    "                    event_smE = file_events.loc[event_number].smE\n",
    "                    \n",
    "                    # Applying the ROI filter\n",
    "                    event_data['roi_filter'] = ((event_smE >= roi_Emin) & (event_smE <= roi_Emax))\n",
    "                \n",
    "                    # Verbosing\n",
    "                    logger.info('  Event energy: {:6.1f} keV  -->  ROI filter: {}'\\\n",
    "                                .format(event_smE / units.keV, event_data['roi_filter']))  \n",
    "\n",
    "                    \n",
    "            # Storing event_data\n",
    "            extend_events_ana_dict(events_dict, event_data)\n",
    "\n",
    "            # Verbosing\n",
    "            if (not(analyzed_events % toUpdate_events)):\n",
    "                print('* Num analyzed events: {}'.format(analyzed_events))\n",
    "            if (analyzed_events == (10 * toUpdate_events)): toUpdate_events *= 10\n",
    "    \n",
    "    \n",
    "    ### STORING ANALYSIS DATA\n",
    "    print('* Total analyzed events: {}'.format(analyzed_events))\n",
    "\n",
    "    # Storing events and voxels dataframes\n",
    "    print('\\n* Storing data in the output file ...\\n  {}\\n'.format(file_out))\n",
    "    store_events_ana_dict(file_out, ana_group_name, events_reco_df, events_dict)\n",
    "    store_voxels_ana_dict(file_out, ana_group_name, voxels_reco_df, voxels_dict)\n",
    "\n",
    "    # Storing event counters as attributes\n",
    "    tracks_filter_events = sum(events_dict['tracks_filter'])\n",
    "    blobs_filter_events  = sum(events_dict['blobs_filter'])\n",
    "    roi_filter_events    = sum(events_dict['roi_filter'])\n",
    "    \n",
    "    store_events_ana_counters(oFile, ana_group_name,\n",
    "                              simulated_events, stored_events,\n",
    "                              smE_filter_events, fid_filter_events,\n",
    "                              tracks_filter_events, blobs_filter_events,\n",
    "                              roi_filter_events)\n",
    "    \n",
    "    \n",
    "    ### Ending ...\n",
    "    oFile.close()\n",
    "    print('* Analysis done !!\\n')\n",
    "    \n",
    "    print('''* Event counters:\n",
    "  Simulated events:     {0:9}\n",
    "  Stored events:        {1:9}\n",
    "  smE_filter events:    {2:9}\n",
    "  fid_filter events:    {3:9}\n",
    "  tracks_filter events: {4:9}\n",
    "  blobs_filter events:  {5:9}\n",
    "  roi_filter events:    {6:9}'''\n",
    "          .format(simulated_events, stored_events, smE_filter_events,\n",
    "                  fid_filter_events, tracks_filter_events, blobs_filter_events,\n",
    "                  roi_filter_events))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_sets import analysis\n",
    "print(analysis.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING THE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "current_ana     = analysis['next100_bb0nu_07_10x10x10']\n",
    "compression     = 'ZLIB4'\n",
    "verbosity_level = 'WARNING'\n",
    "\n",
    "fanal_ana(det_name        = current_ana['det_name'],\n",
    "          event_type      = current_ana['event_type'],\n",
    "          fwhm            = current_ana['fwhm'],\n",
    "          voxel_size      = current_ana['voxel_size'],\n",
    "          track_Eth       = current_ana['track_Eth'],\n",
    "          max_num_tracks  = current_ana['max_num_tracks'],\n",
    "          blob_radius     = current_ana['blob_radius'],\n",
    "          blob_Eth        = current_ana['blob_Eth'],\n",
    "          roi_Emin        = current_ana['roi_Emin'],\n",
    "          roi_Emax        = current_ana['roi_Emax'],\n",
    "          files_in        = current_ana['files_in'],\n",
    "          event_range     = current_ana['event_range'],\n",
    "          file_out        = current_ana['file_out'],\n",
    "          compression     = compression,\n",
    "          verbosity_level = verbosity_level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERBOSING THE ANALYSIS ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DET_NAME        = getattr(DetName, current_ana['det_name'])\n",
    "\n",
    "RECO_GROUP_NAME = get_reco_group_name(current_ana['fwhm'] / units.perCent, current_ana['voxel_size'])\n",
    "\n",
    "ANA_FILE_NAME   = current_ana['file_out']\n",
    "ANA_GROUP_NAME  = get_ana_group_name(current_ana['fwhm'] / units.perCent, current_ana['voxel_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbosing the event counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(ANA_FILE_NAME, mode='r') as iFile:\n",
    "    simulated_events     = iFile.get_node_attr(ANA_GROUP_NAME, 'simulated_events')\n",
    "    stored_events        = iFile.get_node_attr(ANA_GROUP_NAME, 'stored_events')\n",
    "    smE_filter_events    = iFile.get_node_attr(ANA_GROUP_NAME, 'smE_filter_events')\n",
    "    fid_filter_events    = iFile.get_node_attr(ANA_GROUP_NAME, 'fid_filter_events')\n",
    "    tracks_filter_events = iFile.get_node_attr(ANA_GROUP_NAME, 'tracks_filter_events')\n",
    "    blobs_filter_events  = iFile.get_node_attr(ANA_GROUP_NAME, 'blobs_filter_events')\n",
    "    roi_filter_events    = iFile.get_node_attr(ANA_GROUP_NAME, 'roi_filter_events')\n",
    "\n",
    "\n",
    "print('''* Event counters:\n",
    "  Simulated events:     {0:8}\n",
    "  Stored events:        {1:8}\n",
    "  smE_filter events:    {2:8}\n",
    "  fid_filter events:    {3:8}\n",
    "  tracks_filter events: {4:8}\n",
    "  blobs_filter events:  {5:8}\n",
    "  roi_filter events:    {6:8}'''\n",
    "      .format(simulated_events, stored_events, smE_filter_events,\n",
    "              fid_filter_events, tracks_filter_events,\n",
    "              blobs_filter_events, roi_filter_events))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbosing the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_hdf(ANA_FILE_NAME, ANA_GROUP_NAME + '/events')\n",
    "voxels_df = pd.read_hdf(ANA_FILE_NAME, ANA_GROUP_NAME + '/voxels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_smE_True    = events_df[events_df.smE_filter]\n",
    "events_df_fid_True    = events_df[events_df.fid_filter]\n",
    "events_df_tracks_True = events_df[events_df.tracks_filter]\n",
    "events_df_blobs_True  = events_df[events_df.blobs_filter]\n",
    "events_df_roi_True    = events_df[events_df.roi_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_toShow = ['smE', 'num_tracks', 'track0_E', 'track0_voxels', 'track0_length',\n",
    "                  'tracks_filter', 'blob1_E', 'blob2_E', 'blobs_filter', 'roi_filter']\n",
    "#events_df_fid_True[columns_toShow].head()\n",
    "events_df_tracks_True[columns_toShow].head()\n",
    "#events_df_blobs_True[columns_toShow].head()\n",
    "#events_df_roi_True[columns_toShow].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_df_tracks_True.columns\n",
    "columns_toShow = ['num_MChits', 'smE', 'smE_filter', 'num_voxels', 'voxel_sizeX', 'voxel_sizeY',\n",
    "                  'voxel_sizeZ', 'voxels_minZ', 'voxels_maxZ', 'voxels_maxRad',\n",
    "                  'veto_energy', 'fid_filter', 'num_tracks', 'blob1_E', 'blob2_E']\n",
    "events_df_fid_True[events_df_fid_True.num_voxels <= 10][columns_toShow].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voxels_df.loc[214].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating some histograms ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,4))\n",
    "\n",
    "counters_toPlot = {'smE_filter Events': smE_filter_events,\n",
    "                   'fid_filter Events': fid_filter_events,\n",
    "                   'tracks_filter Events': tracks_filter_events,\n",
    "                   'blobs_filter Events': blobs_filter_events,\n",
    "                   'roi_filter Events': roi_filter_events}\n",
    "\n",
    "plt.bar(range(len(counters_toPlot)), list(counters_toPlot.values()), align='center',\n",
    "        color=['b', 'r', 'c', 'y', 'm'], yerr=np.sqrt([smE_filter_events, fid_filter_events,\n",
    "                                                       tracks_filter_events, blobs_filter_events,\n",
    "                                                       roi_filter_events]))\n",
    "plt.xticks(range(len(counters_toPlot)), list(counters_toPlot.keys()), rotation='30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting number of tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "num_bins = 10\n",
    "\n",
    "#plt.hist(events_df_fid_True.num_tracks, num_bins, [0, 10])\n",
    "plt.hist(events_df_fid_True.num_tracks, num_bins, [0, 10])\n",
    "plt.xlabel('Num Tracks', size=12)\n",
    "plt.ylabel('Num. events', size=12)\n",
    "plt.title('{} - Number of reconstructed tracks'.format(current_ana['event_type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting energies, number of voxels and lengths of the three hottest tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18, 18))\n",
    "num_E_bins = 20\n",
    "num_voxels_bins = 20\n",
    "num_length_bins = 20\n",
    "\n",
    "# First track plots\n",
    "plotting_events = events_df_fid_True[events_df_fid_True.num_tracks >= 1]\n",
    "ax1 = fig.add_subplot(3, 3, 1)\n",
    "plt.hist(plotting_events.track0_E, num_E_bins, [0., 2.5])\n",
    "plt.title('Track 0 Energy [MeV]', size=12)\n",
    "\n",
    "ax2 = fig.add_subplot(3, 3, 4)\n",
    "plt.hist(plotting_events.track0_voxels, num_voxels_bins, [0, 40])\n",
    "plt.title('Track 0 - Num Voxels', size=12)\n",
    "\n",
    "ax3 = fig.add_subplot(3, 3, 7)\n",
    "plt.hist(plotting_events.track0_length, num_length_bins, [0, 200])\n",
    "plt.title('Track 0 - Length', size=12)\n",
    "\n",
    "# Second track plots\n",
    "plotting_events = events_df_fid_True[events_df_fid_True.num_tracks >= 2]\n",
    "ax4 = fig.add_subplot(3, 3, 2)\n",
    "plt.hist(plotting_events.track1_E, num_E_bins, [0., 1.0])\n",
    "plt.title('Track 1 Energy [MeV]', size=12)\n",
    "\n",
    "ax5 = fig.add_subplot(3, 3, 5)\n",
    "plt.hist(plotting_events.track1_voxels, num_voxels_bins, [0, 20])\n",
    "plt.title('Track 1 - Num Voxels', size=12)\n",
    "\n",
    "ax6 = fig.add_subplot(3, 3, 8)\n",
    "plt.hist(plotting_events.track1_length, num_length_bins, [0, 100])\n",
    "plt.title('Track 1 - Length', size=12)\n",
    "\n",
    "# Third track plots\n",
    "plotting_events = events_df_fid_True[events_df_fid_True.num_tracks >= 3]\n",
    "ax7 = fig.add_subplot(3, 3, 3)\n",
    "plt.hist(plotting_events.track2_E, num_E_bins, [0., 1.0])\n",
    "plt.title('Track 2 Energy [MeV]', size=12)\n",
    "\n",
    "ax8 = fig.add_subplot(3, 3, 6)\n",
    "plt.hist(plotting_events.track2_voxels, num_voxels_bins, [0, 20])\n",
    "plt.title('Track 2 - Num Voxels', size=12)\n",
    "\n",
    "ax9 = fig.add_subplot(3, 3, 9)\n",
    "plt.hist(plotting_events.track2_length, num_length_bins, [0, 50])\n",
    "plt.title('Track 2 - Length', size=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy histogram of events passing the tracks filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "num_bins = 20\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.hist(events_df_tracks_True.track0_E, num_bins, [2.4, 2.5])\n",
    "plt.xlabel('Track Energy [MeV]', size=14)\n",
    "plt.title('{} - Track 0 Energy'.format(current_ana['event_type']))\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.hist(events_df_tracks_True.smE, num_bins, [2.4, 2.5])\n",
    "plt.xlabel('Event Energy [MeV]', size=14)\n",
    "plt.title('{} - Event Energy'.format(current_ana['event_type']))\n",
    "\n",
    "# As expected, both histograms are the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms of blob energies ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "num_bins = 30\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.hist(events_df_tracks_True.blob1_E, num_bins, [0, 1.5])\n",
    "plt.xlabel('Blob1 Energy [MeV]')\n",
    "plt.title('{} - Blob1 Energy [MeV]'.format(current_ana['event_type']), size=14)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.hist(events_df_tracks_True.blob2_E, num_bins, [0, 1.5])\n",
    "plt.xlabel('Blob2 Energy [MeV]')\n",
    "plt.title('{} - Blob2 Energy [MeV]'.format(current_ana['event_type']), size=14)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (7,6))\n",
    "plt.hist2d(events_df_tracks_True.blob1_E, events_df_tracks_True.blob2_E, num_bins,\n",
    "           [[0, 1.5], [0, 1.5]], norm=LogNorm())\n",
    "plt.xlabel('Highest Blob Energy [MeV]')\n",
    "plt.ylabel('Lowest Blob Energy [MeV]')\n",
    "plt.title('{} - Blobs Energies [MeV]'.format(current_ana['event_type']), size=14)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI energy ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(ANA_FILE_NAME, mode='r') as iFile:\n",
    "    ROI_E_MIN = iFile.get_node_attr(ANA_GROUP_NAME, 'roi_Emin')\n",
    "    ROI_E_MAX  = iFile.get_node_attr(ANA_GROUP_NAME, 'roi_Emax')\n",
    "\n",
    "fig = plt.figure(figsize = (7,6))\n",
    "num_bins = int((ROI_E_MAX - ROI_E_MIN) / units.keV)\n",
    "\n",
    "plt.hist(events_df_roi_True.smE, num_bins, [ROI_E_MIN, ROI_E_MAX])\n",
    "plt.xlabel('Event Energy [MeV]')\n",
    "plt.title('{} - Event Energy'.format(current_ana['event_type']), size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_df[voxels_df.negli].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_toShow = ['E', 'newE', 'track_id']\n",
    "voxels_df.loc[events_df_fid_True.index, columns_toShow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing and plotting the MC info of an event ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event_to_print = 149\n",
    "#\n",
    "#sim_files = []\n",
    "#with tb.open_file(ANA_FILE_NAME, mode='r') as iFile:\n",
    "#    reco_file_names = iFile.get_node_attr(ANA_GROUP_NAME, 'input_reco_files')\n",
    "#    \n",
    "#    for reco_file_name in reco_file_names:\n",
    "#        with tb.open_file(reco_file_name, mode='r') as iRecoFile:\n",
    "#            sim_files += iRecoFile.get_node_attr(RECO_GROUP_NAME, 'input_sim_files')\n",
    "#            \n",
    "#print_mc_event(event_to_print, sim_files, with_hits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(files_list)\n",
    "#event_to_plot = 149\n",
    "#plot_mc_event(event_to_plot, sim_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            event_voxels = file_voxels.loc[event_number]\n",
    "            voxel_dimensions = (event_df.voxel_sizeX,\n",
    "                                event_df.voxel_sizeY,\n",
    "                                event_df.voxel_sizeZ)\n",
    "\n",
    "            ic_voxels = []\n",
    "            for voxel in event_voxels.iterrows():\n",
    "                ic_voxel = Voxel(voxel.X, voxel.Y, voxel.Z, voxel.E, voxel_dimensions)\n",
    "                ic_voxels.append(ic_voxel)            \n",
    "            \n",
    "            # Make tracks\n",
    "            event_tracks = make_track_graphs(ic_voxels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
